{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24417a82",
   "metadata": {},
   "source": [
    "# Classic_Recommendation_Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bbe1bde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taek5\\AppData\\Local\\Temp\\ipykernel_12824\\3587479969.py:6: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  books = pd.read_csv(data_path+'BX-Books-comma-sep.csv', sep=',', error_bad_lines=False, warn_bad_lines=False, encoding=\"latin-1\", index_col = 0)\n",
      "C:\\Users\\taek5\\AppData\\Local\\Temp\\ipykernel_12824\\3587479969.py:6: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  books = pd.read_csv(data_path+'BX-Books-comma-sep.csv', sep=',', error_bad_lines=False, warn_bad_lines=False, encoding=\"latin-1\", index_col = 0)\n",
      "C:\\Users\\taek5\\AppData\\Local\\Temp\\ipykernel_12824\\3587479969.py:6: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv(data_path+'BX-Books-comma-sep.csv', sep=',', error_bad_lines=False, warn_bad_lines=False, encoding=\"latin-1\", index_col = 0)\n",
      "C:\\Users\\taek5\\AppData\\Local\\Temp\\ipykernel_12824\\3587479969.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  users = pd.read_csv(data_path+'BX-Users-comma-sep.csv', sep=',', error_bad_lines=False, warn_bad_lines=False,encoding=\"latin-1\", index_col = 0)\n",
      "C:\\Users\\taek5\\AppData\\Local\\Temp\\ipykernel_12824\\3587479969.py:7: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  users = pd.read_csv(data_path+'BX-Users-comma-sep.csv', sep=',', error_bad_lines=False, warn_bad_lines=False,encoding=\"latin-1\", index_col = 0)\n",
      "C:\\Users\\taek5\\AppData\\Local\\Temp\\ipykernel_12824\\3587479969.py:8: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  ratings = pd.read_csv(data_path+'BX-Book-Ratings-comma-sep.csv', sep=',', error_bad_lines=False, warn_bad_lines=False, encoding=\"latin-1\", index_col = 0)\n",
      "C:\\Users\\taek5\\AppData\\Local\\Temp\\ipykernel_12824\\3587479969.py:8: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  ratings = pd.read_csv(data_path+'BX-Book-Ratings-comma-sep.csv', sep=',', error_bad_lines=False, warn_bad_lines=False, encoding=\"latin-1\", index_col = 0)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "import pandas as pd\n",
    "\n",
    "data_path = 'C:/Users/taek5/Desktop/TG/RecommenderSystems/data/book_crossing/'\n",
    "\n",
    "books = pd.read_csv(data_path+'BX-Books-comma-sep.csv', sep=',', error_bad_lines=False, warn_bad_lines=False, encoding=\"latin-1\", index_col = 0)\n",
    "users = pd.read_csv(data_path+'BX-Users-comma-sep.csv', sep=',', error_bad_lines=False, warn_bad_lines=False,encoding=\"latin-1\", index_col = 0)\n",
    "ratings = pd.read_csv(data_path+'BX-Book-Ratings-comma-sep.csv', sep=',', error_bad_lines=False, warn_bad_lines=False, encoding=\"latin-1\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fdb0b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter books with at least min_book_ratings ratings\n",
    "min_book_ratings = 10\n",
    "book_ratings_counts = ratings['Book-Title'].value_counts()\n",
    "filtered_books = book_ratings_counts[book_ratings_counts >= min_book_ratings].index\n",
    "ratings = ratings[ratings['Book-Title'].isin(filtered_books)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e5fb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2313</td>\n",
       "      <td>5</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6543</td>\n",
       "      <td>0</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8680</td>\n",
       "      <td>5</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10314</td>\n",
       "      <td>9</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23768</td>\n",
       "      <td>0</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031125</th>\n",
       "      <td>276688</td>\n",
       "      <td>0</td>\n",
       "      <td>Coyote Waits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031126</th>\n",
       "      <td>276688</td>\n",
       "      <td>0</td>\n",
       "      <td>Sacred Clowns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031128</th>\n",
       "      <td>276688</td>\n",
       "      <td>0</td>\n",
       "      <td>Mrs. Pollifax and the Second Thief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031131</th>\n",
       "      <td>276688</td>\n",
       "      <td>0</td>\n",
       "      <td>Mostly Harmless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031132</th>\n",
       "      <td>276688</td>\n",
       "      <td>7</td>\n",
       "      <td>Gray Matter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>491897 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         User-ID  Book-Rating                          Book-Title\n",
       "1           2313            5                Flesh Tones: A Novel\n",
       "2           6543            0                Flesh Tones: A Novel\n",
       "3           8680            5                Flesh Tones: A Novel\n",
       "4          10314            9                Flesh Tones: A Novel\n",
       "5          23768            0                Flesh Tones: A Novel\n",
       "...          ...          ...                                 ...\n",
       "1031125   276688            0                        Coyote Waits\n",
       "1031126   276688            0                       Sacred Clowns\n",
       "1031128   276688            0  Mrs. Pollifax and the Second Thief\n",
       "1031131   276688            0                     Mostly Harmless\n",
       "1031132   276688            7                         Gray Matter\n",
       "\n",
       "[491897 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter users with at least min_user_ratings books\n",
    "min_user_ratings = 5\n",
    "user_rating_counts = ratings['User-ID'].value_counts()\n",
    "filtered_users = user_rating_counts[user_rating_counts >= min_user_ratings].index\n",
    "ratings = ratings[ratings['User-ID'].isin(filtered_users)]\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4f5dc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the user-item matrix\n",
    "user_item_matrix = ratings.pivot_table(index = 'User-ID', columns = 'Book-Title', values = 'Book-Rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d8af7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split user indices into train and test sets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "user_indices = np.arange(user_item_matrix.shape[0])\n",
    "train_user_indices, test_user_indices = train_test_split(user_indices, test_size = 0.001, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80caf29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Score-Based Recommendations:\n",
      "1. Das Versprechen. Requiem auf den Kriminalroman.\n",
      "2. The Delaney Woman\n",
      "3. In God We Trust: All Others Pay Cash\n",
      "4. Secrets of the Night\n",
      "5. Venus Envy\n",
      "6. The Bishop and the Three Kings: A Blackie Ryan Mystery (Blackie Ryan Novels)\n",
      "7. The Discworld Mapp\n",
      "8. The Red Scream\n",
      "9. Q\n",
      "10. Hullabaloo in the Guava Orchard\n"
     ]
    }
   ],
   "source": [
    "def random_recommendation(ratings, n = 10):\n",
    "    unique_books = ratings['Book-Title'].unique()\n",
    "    random_books = np.random.choice(unique_books, size = n, replace = False)\n",
    "    return random_books\n",
    "\n",
    "random_books = random_recommendation(ratings, n = 10)\n",
    "print('Random Score-Based Recommendations:')\n",
    "for i,book in enumerate(random_books, 1):\n",
    "    print(f\"{i}. {book}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81779ffb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Popularity-Based Recommendations:\n",
      "1. Wild Animus\n",
      "2. The Lovely Bones: A Novel\n",
      "3. The Da Vinci Code\n",
      "4. The Nanny Diaries: A Novel\n",
      "5. Bridget Jones's Diary\n",
      "6. A Painted House\n",
      "7. The Secret Life of Bees\n",
      "8. Divine Secrets of the Ya-Ya Sisterhood: A Novel\n",
      "9. Angels &amp; Demons\n",
      "10. Life of Pi\n"
     ]
    }
   ],
   "source": [
    "def popularity_recommendation(ratings, n = 10):\n",
    "    popular_books = ratings.groupby('Book-Title')['Book-Title'].count().sort_values(ascending = False).head(n).index\n",
    "    return popular_books\n",
    "\n",
    "popular_books = popularity_recommendation(ratings, n = 10)\n",
    "print(\"\\nPopularity-Based Recommendations:\")\n",
    "for i, book in enumerate(popular_books, 1):\n",
    "    print(f\"{i}. {book}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b189fe1e",
   "metadata": {},
   "source": [
    "## Association_Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "af608596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the UCI Machine Learning Repository\n",
    "import pandas as pd\n",
    "\n",
    "data_path = 'C:/Users/taek5/Desktop/TG/RecommenderSystems/data/online_retail/'\n",
    "online_retail_data = pd.read_excel(data_path + 'Online Retail.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f5a24d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "online_retail_data['Description'] = online_retail_data['Description'].str.strip()\n",
    "online_retail_data = online_retail_data.dropna(axis = 0, subset = ['InvoiceNo'])\n",
    "online_retail_data['InvoiceNo'] = online_retail_data['InvoiceNo'].astype('str')\n",
    "online_retail_data = online_retail_data[~online_retail_data['InvoiceNo'].str.contains('C')] # 취소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "58301545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taek5\\anaconda3\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:109: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Convert transaction data into a basker foramt\n",
    "basket = (online_retail_data[online_retail_data['Country'] == 'United Kingdom']\n",
    "          .groupby(['InvoiceNo', 'Description'])['Quantity']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('InvoiceNo'))\n",
    "\n",
    "# Convert the quantities into 0/1 (0: not in the basket, 1: in the basket)\n",
    "def encode_units(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >= 1:\n",
    "        return 1\n",
    "    \n",
    "basket_sets = basket.applymap(encode_units)\n",
    "\n",
    "# Use the Apriori algorithm to find frequent itemsets\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "frequent_itemsets = apriori(basket_sets, min_support = 0.03, use_colnames = True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric = 'lift', min_threshold = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c5a1bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rules by a minimum lift and confidence\n",
    "filtered_rules = rules[(rules['lift'] >= 3.0) & (rules['confidence'] >= 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a886ac91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ALARM CLOCK BAKELIKE GREEN)</td>\n",
       "      <td>(ALARM CLOCK BAKELIKE RED)</td>\n",
       "      <td>0.030160</td>\n",
       "      <td>0.642694</td>\n",
       "      <td>12.900183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(ALARM CLOCK BAKELIKE RED)</td>\n",
       "      <td>(ALARM CLOCK BAKELIKE GREEN)</td>\n",
       "      <td>0.030160</td>\n",
       "      <td>0.605376</td>\n",
       "      <td>12.900183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(GREEN REGENCY TEACUP AND SAUCER)</td>\n",
       "      <td>(PINK REGENCY TEACUP AND SAUCER)</td>\n",
       "      <td>0.030910</td>\n",
       "      <td>0.617773</td>\n",
       "      <td>16.403939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(PINK REGENCY TEACUP AND SAUCER)</td>\n",
       "      <td>(GREEN REGENCY TEACUP AND SAUCER)</td>\n",
       "      <td>0.030910</td>\n",
       "      <td>0.820768</td>\n",
       "      <td>16.403939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(GREEN REGENCY TEACUP AND SAUCER)</td>\n",
       "      <td>(ROSES REGENCY TEACUP AND SAUCER)</td>\n",
       "      <td>0.037553</td>\n",
       "      <td>0.750535</td>\n",
       "      <td>14.639752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(ROSES REGENCY TEACUP AND SAUCER)</td>\n",
       "      <td>(GREEN REGENCY TEACUP AND SAUCER)</td>\n",
       "      <td>0.037553</td>\n",
       "      <td>0.732497</td>\n",
       "      <td>14.639752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(JUMBO  BAG BAROQUE BLACK WHITE)</td>\n",
       "      <td>(JUMBO BAG RED RETROSPOT)</td>\n",
       "      <td>0.030535</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>6.033290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(JUMBO BAG PINK POLKADOT)</td>\n",
       "      <td>(JUMBO BAG RED RETROSPOT)</td>\n",
       "      <td>0.042053</td>\n",
       "      <td>0.677308</td>\n",
       "      <td>6.523895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(JUMBO SHOPPER VINTAGE RED PAISLEY)</td>\n",
       "      <td>(JUMBO BAG RED RETROSPOT)</td>\n",
       "      <td>0.035196</td>\n",
       "      <td>0.579876</td>\n",
       "      <td>5.585425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(JUMBO STORAGE BAG SUKI)</td>\n",
       "      <td>(JUMBO BAG RED RETROSPOT)</td>\n",
       "      <td>0.037392</td>\n",
       "      <td>0.617699</td>\n",
       "      <td>5.949737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            antecedents                        consequents  \\\n",
       "0          (ALARM CLOCK BAKELIKE GREEN)         (ALARM CLOCK BAKELIKE RED)   \n",
       "1            (ALARM CLOCK BAKELIKE RED)       (ALARM CLOCK BAKELIKE GREEN)   \n",
       "2     (GREEN REGENCY TEACUP AND SAUCER)   (PINK REGENCY TEACUP AND SAUCER)   \n",
       "3      (PINK REGENCY TEACUP AND SAUCER)  (GREEN REGENCY TEACUP AND SAUCER)   \n",
       "4     (GREEN REGENCY TEACUP AND SAUCER)  (ROSES REGENCY TEACUP AND SAUCER)   \n",
       "5     (ROSES REGENCY TEACUP AND SAUCER)  (GREEN REGENCY TEACUP AND SAUCER)   \n",
       "6      (JUMBO  BAG BAROQUE BLACK WHITE)          (JUMBO BAG RED RETROSPOT)   \n",
       "8             (JUMBO BAG PINK POLKADOT)          (JUMBO BAG RED RETROSPOT)   \n",
       "10  (JUMBO SHOPPER VINTAGE RED PAISLEY)          (JUMBO BAG RED RETROSPOT)   \n",
       "13             (JUMBO STORAGE BAG SUKI)          (JUMBO BAG RED RETROSPOT)   \n",
       "\n",
       "     support  confidence       lift  \n",
       "0   0.030160    0.642694  12.900183  \n",
       "1   0.030160    0.605376  12.900183  \n",
       "2   0.030910    0.617773  16.403939  \n",
       "3   0.030910    0.820768  16.403939  \n",
       "4   0.037553    0.750535  14.639752  \n",
       "5   0.037553    0.732497  14.639752  \n",
       "6   0.030535    0.626374   6.033290  \n",
       "8   0.042053    0.677308   6.523895  \n",
       "10  0.035196    0.579876   5.585425  \n",
       "13  0.037392    0.617699   5.949737  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the association rules\n",
    "filtered_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9329b1",
   "metadata": {},
   "source": [
    "## Contents Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cb8e7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.66666667 0.40824829 0.81649658]\n",
      " [0.66666667 1.         0.81649658 0.40824829]\n",
      " [0.40824829 0.81649658 1.         0.        ]\n",
      " [0.81649658 0.40824829 0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Define the matrix\n",
    "matrix = np.array([[1, 1, 1, 0],\n",
    "                   [1, 0, 1, 1],\n",
    "                   [1, 0, 0, 1],\n",
    "                   [0, 1, 1, 0]])\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity_matrix = cosine_similarity(matrix)\n",
    "\n",
    "# Print the similarity matrix\n",
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddf1742",
   "metadata": {},
   "source": [
    "### Bag of Words 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "805dc8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 'love', 'watching', 'movies'], ['i', 'enjoy', 'reading', 'books'], ['i', 'love', 'reading', 'and', 'watching', 'movies']]\n",
      "\n",
      "\n",
      "[Counter({'i': 1, 'love': 1, 'watching': 1, 'movies': 1}), Counter({'i': 1, 'enjoy': 1, 'reading': 1, 'books': 1}), Counter({'i': 1, 'love': 1, 'reading': 1, 'and': 1, 'watching': 1, 'movies': 1})]\n",
      "\n",
      "\n",
      "Bag of Words representation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>love</th>\n",
       "      <th>watching</th>\n",
       "      <th>movies</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>reading</th>\n",
       "      <th>books</th>\n",
       "      <th>and</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Document 1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document 2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document 3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            i  love  watching  movies  enjoy  reading  books  and\n",
       "Document 1  1   1.0       1.0     1.0    0.0      0.0    0.0  0.0\n",
       "Document 2  1   0.0       0.0     0.0    1.0      1.0    1.0  0.0\n",
       "Document 3  1   1.0       1.0     1.0    0.0      1.0    0.0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Sample sentences\n",
    "documents = [\n",
    "    \"I love watching movies\",\n",
    "    \"I enjoy reading books\",\n",
    "    \"I love reading and watching movies\"\n",
    "]\n",
    "\n",
    "# Preprocess sentences: lower case and tokenize\n",
    "tokenized_documents = [doc.lower().split() for doc in documents]\n",
    "print(tokenized_documents)\n",
    "\n",
    "print('\\n')\n",
    "# Calculate word frequencies for each document\n",
    "word_frequencies = [Counter(doc) for doc in tokenized_documents]\n",
    "print(word_frequencies)\n",
    "\n",
    "print('\\n')\n",
    "# Create a DataFrame to display the results\n",
    "bow_df = pd.DataFrame(word_frequencies, index = ['Document 1', 'Document 2', 'Document 3']).fillna(0)\n",
    "print(\"Bag of Words representation:\")\n",
    "display(bow_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487223c5",
   "metadata": {},
   "source": [
    "### TF-IDF 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d5fd6ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized_documents:\n",
      "[['i', 'love', 'watching', 'movies'], ['i', 'enjoy', 'reading', 'books'], ['i', 'love', 'reading', 'and', 'watching', 'movies']]\n",
      "\n",
      "\n",
      "[{'i': 0.25, 'love': 0.25, 'watching': 0.25, 'movies': 0.25}, {'i': 0.25, 'enjoy': 0.25, 'reading': 0.25, 'books': 0.25}, {'i': 0.16666666666666666, 'love': 0.16666666666666666, 'reading': 0.16666666666666666, 'and': 0.16666666666666666, 'watching': 0.16666666666666666, 'movies': 0.16666666666666666}]\n",
      "\n",
      "\n",
      "Term Frequencies DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>love</th>\n",
       "      <th>watching</th>\n",
       "      <th>movies</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>reading</th>\n",
       "      <th>books</th>\n",
       "      <th>and</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Document 1</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document 2</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document 3</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   i      love  watching    movies  enjoy   reading  books  \\\n",
       "Document 1  0.250000  0.250000  0.250000  0.250000   0.00  0.000000   0.00   \n",
       "Document 2  0.250000  0.000000  0.000000  0.000000   0.25  0.250000   0.25   \n",
       "Document 3  0.166667  0.166667  0.166667  0.166667   0.00  0.166667   0.00   \n",
       "\n",
       "                 and  \n",
       "Document 1  0.000000  \n",
       "Document 2  0.000000  \n",
       "Document 3  0.166667  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Inverse Document Frequencies DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>books</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>reading</th>\n",
       "      <th>watching</th>\n",
       "      <th>movies</th>\n",
       "      <th>i</th>\n",
       "      <th>love</th>\n",
       "      <th>and</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IDF</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        books     enjoy   reading  watching    movies    i      love       and\n",
       "IDF  1.098612  1.098612  0.405465  0.405465  0.405465  0.0  0.405465  1.098612"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TF-IDF Values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'i': 0.0,\n",
       "  'love': 0.1013662770270411,\n",
       "  'watching': 0.1013662770270411,\n",
       "  'movies': 0.1013662770270411},\n",
       " {'i': 0.0,\n",
       "  'enjoy': 0.27465307216702745,\n",
       "  'reading': 0.1013662770270411,\n",
       "  'books': 0.27465307216702745},\n",
       " {'i': 0.0,\n",
       "  'love': 0.06757751801802739,\n",
       "  'reading': 0.06757751801802739,\n",
       "  'and': 0.1831020481113516,\n",
       "  'watching': 0.06757751801802739,\n",
       "  'movies': 0.06757751801802739}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# Sample sentences\n",
    "documents = [\n",
    "    \"I love watching movies\",\n",
    "    \"I enjoy reading books\",\n",
    "    \"I love reading and watching movies\"\n",
    "]\n",
    "\n",
    "# Preprocess sentences: lower case and tokenize\n",
    "tokenized_documents = [doc.lower().split() for doc in documents]\n",
    "print(\"tokenized_documents:\")\n",
    "print(tokenized_documents)\n",
    "print('\\n')\n",
    "\n",
    "# Calculate term frequency\n",
    "def term_frequency(doc):\n",
    "    term_count = Counter(doc)\n",
    "    \n",
    "    total_terms = len(doc)\n",
    "    return {term: count / total_terms for term, count in term_count.items()}\n",
    "\n",
    "tf_values = [term_frequency(doc) for doc in tokenized_documents]\n",
    "print(tf_values)\n",
    "print('\\n')\n",
    "\n",
    "tf_df = pd.DataFrame(tf_values, index = [\"Document 1\", \"Document 2\", \"Document 3\"]).fillna(0)\n",
    "print(\"Term Frequencies DataFrame:\")\n",
    "display(tf_df)\n",
    "print('\\n')\n",
    "\n",
    "# Calculate inverse document frequency\n",
    "def inverse_document_frequency(docs):\n",
    "    total_docs = len(docs)\n",
    "    \n",
    "    unique_terms = set(term for doc in docs for term in doc)\n",
    "    \n",
    "    term_doc_counts = {term: sum(1 for doc in docs if term in doc) for term in unique_terms}\n",
    "    \n",
    "    return {term: math.log(total_docs / count) for term, count in term_doc_counts.items()}\n",
    "\n",
    "idf_values = inverse_document_frequency(tokenized_documents)\n",
    "idf_df = pd.DataFrame([idf_values], index = ['IDF'])\n",
    "print(\"Inverse Document Frequencies DataFrame:\")\n",
    "display(idf_df)\n",
    "print('\\n')\n",
    "\n",
    "# Calculate TF-IDF\n",
    "def tf_idf(tf, idf):\n",
    "    return {term: tf_val * idf[term] for term, tf_val in tf.items()}\n",
    "\n",
    "tf_idf_values = [tf_idf(tf, idf_values) for tf in tf_values]\n",
    "print(\"TF-IDF Values:\")\n",
    "display(tf_idf_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
