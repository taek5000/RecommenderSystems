{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06703a4a",
   "metadata": {},
   "source": [
    "# Classic_Recommendation_Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db330d36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taek5\\AppData\\Local\\Temp\\ipykernel_19060\\3587479969.py:6: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  books = pd.read_csv(data_path+'BX-Books-comma-sep.csv', sep=',', error_bad_lines=False, warn_bad_lines=False, encoding=\"latin-1\", index_col = 0)\n",
      "C:\\Users\\taek5\\AppData\\Local\\Temp\\ipykernel_19060\\3587479969.py:6: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  books = pd.read_csv(data_path+'BX-Books-comma-sep.csv', sep=',', error_bad_lines=False, warn_bad_lines=False, encoding=\"latin-1\", index_col = 0)\n",
      "C:\\Users\\taek5\\AppData\\Local\\Temp\\ipykernel_19060\\3587479969.py:6: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv(data_path+'BX-Books-comma-sep.csv', sep=',', error_bad_lines=False, warn_bad_lines=False, encoding=\"latin-1\", index_col = 0)\n",
      "C:\\Users\\taek5\\AppData\\Local\\Temp\\ipykernel_19060\\3587479969.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  users = pd.read_csv(data_path+'BX-Users-comma-sep.csv', sep=',', error_bad_lines=False, warn_bad_lines=False,encoding=\"latin-1\", index_col = 0)\n",
      "C:\\Users\\taek5\\AppData\\Local\\Temp\\ipykernel_19060\\3587479969.py:7: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  users = pd.read_csv(data_path+'BX-Users-comma-sep.csv', sep=',', error_bad_lines=False, warn_bad_lines=False,encoding=\"latin-1\", index_col = 0)\n",
      "C:\\Users\\taek5\\AppData\\Local\\Temp\\ipykernel_19060\\3587479969.py:8: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  ratings = pd.read_csv(data_path+'BX-Book-Ratings-comma-sep.csv', sep=',', error_bad_lines=False, warn_bad_lines=False, encoding=\"latin-1\", index_col = 0)\n",
      "C:\\Users\\taek5\\AppData\\Local\\Temp\\ipykernel_19060\\3587479969.py:8: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  ratings = pd.read_csv(data_path+'BX-Book-Ratings-comma-sep.csv', sep=',', error_bad_lines=False, warn_bad_lines=False, encoding=\"latin-1\", index_col = 0)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "import pandas as pd\n",
    "\n",
    "data_path = 'C:/Users/taek5/Desktop/TG/RecommenderSystems/data/book_crossing/'\n",
    "\n",
    "books = pd.read_csv(data_path+'BX-Books-comma-sep.csv', sep=',', error_bad_lines=False, warn_bad_lines=False, encoding=\"latin-1\", index_col = 0)\n",
    "users = pd.read_csv(data_path+'BX-Users-comma-sep.csv', sep=',', error_bad_lines=False, warn_bad_lines=False,encoding=\"latin-1\", index_col = 0)\n",
    "ratings = pd.read_csv(data_path+'BX-Book-Ratings-comma-sep.csv', sep=',', error_bad_lines=False, warn_bad_lines=False, encoding=\"latin-1\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fdb0b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter books with at least min_book_ratings ratings\n",
    "min_book_ratings = 10\n",
    "book_ratings_counts = ratings['Book-Title'].value_counts()\n",
    "filtered_books = book_ratings_counts[book_ratings_counts >= min_book_ratings].index\n",
    "ratings = ratings[ratings['Book-Title'].isin(filtered_books)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e5fb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2313</td>\n",
       "      <td>5</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6543</td>\n",
       "      <td>0</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8680</td>\n",
       "      <td>5</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10314</td>\n",
       "      <td>9</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23768</td>\n",
       "      <td>0</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031125</th>\n",
       "      <td>276688</td>\n",
       "      <td>0</td>\n",
       "      <td>Coyote Waits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031126</th>\n",
       "      <td>276688</td>\n",
       "      <td>0</td>\n",
       "      <td>Sacred Clowns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031128</th>\n",
       "      <td>276688</td>\n",
       "      <td>0</td>\n",
       "      <td>Mrs. Pollifax and the Second Thief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031131</th>\n",
       "      <td>276688</td>\n",
       "      <td>0</td>\n",
       "      <td>Mostly Harmless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031132</th>\n",
       "      <td>276688</td>\n",
       "      <td>7</td>\n",
       "      <td>Gray Matter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>491897 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         User-ID  Book-Rating                          Book-Title\n",
       "1           2313            5                Flesh Tones: A Novel\n",
       "2           6543            0                Flesh Tones: A Novel\n",
       "3           8680            5                Flesh Tones: A Novel\n",
       "4          10314            9                Flesh Tones: A Novel\n",
       "5          23768            0                Flesh Tones: A Novel\n",
       "...          ...          ...                                 ...\n",
       "1031125   276688            0                        Coyote Waits\n",
       "1031126   276688            0                       Sacred Clowns\n",
       "1031128   276688            0  Mrs. Pollifax and the Second Thief\n",
       "1031131   276688            0                     Mostly Harmless\n",
       "1031132   276688            7                         Gray Matter\n",
       "\n",
       "[491897 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter users with at least min_user_ratings books\n",
    "min_user_ratings = 5\n",
    "user_rating_counts = ratings['User-ID'].value_counts()\n",
    "filtered_users = user_rating_counts[user_rating_counts >= min_user_ratings].index\n",
    "ratings = ratings[ratings['User-ID'].isin(filtered_users)]\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4f5dc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the user-item matrix\n",
    "user_item_matrix = ratings.pivot_table(index = 'User-ID', columns = 'Book-Title', values = 'Book-Rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d8af7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split user indices into train and test sets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "user_indices = np.arange(user_item_matrix.shape[0])\n",
    "train_user_indices, test_user_indices = train_test_split(user_indices, test_size = 0.001, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80caf29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Score-Based Recommendations:\n",
      "1. Navy Blues\n",
      "2. The Standoff\n",
      "3. Forever After\n",
      "4. Le Zebre\n",
      "5. After Tex\n",
      "6. FORREST GUMP (Movie Tie in)\n",
      "7. The Caves of Steel\n",
      "8. Junie B. Jones and the  Stupid Smelly Bus (Junie B. Jones 1, paper)\n",
      "9. Dracula (World's Classics)\n",
      "10. Shiloh and Other Stories\n"
     ]
    }
   ],
   "source": [
    "def random_recommendation(ratings, n = 10):\n",
    "    unique_books = ratings['Book-Title'].unique()\n",
    "    random_books = np.random.choice(unique_books, size = n, replace = False)\n",
    "    return random_books\n",
    "\n",
    "random_books = random_recommendation(ratings, n = 10)\n",
    "print('Random Score-Based Recommendations:')\n",
    "for i,book in enumerate(random_books, 1):\n",
    "    print(f\"{i}. {book}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81779ffb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Popularity-Based Recommendations:\n",
      "1. Wild Animus\n",
      "2. The Lovely Bones: A Novel\n",
      "3. The Da Vinci Code\n",
      "4. The Nanny Diaries: A Novel\n",
      "5. Bridget Jones's Diary\n",
      "6. A Painted House\n",
      "7. The Secret Life of Bees\n",
      "8. Divine Secrets of the Ya-Ya Sisterhood: A Novel\n",
      "9. Angels &amp; Demons\n",
      "10. Life of Pi\n"
     ]
    }
   ],
   "source": [
    "def popularity_recommendation(ratings, n = 10):\n",
    "    popular_books = ratings.groupby('Book-Title')['Book-Title'].count().sort_values(ascending = False).head(n).index\n",
    "    return popular_books\n",
    "\n",
    "popular_books = popularity_recommendation(ratings, n = 10)\n",
    "print(\"\\nPopularity-Based Recommendations:\")\n",
    "for i, book in enumerate(popular_books, 1):\n",
    "    print(f\"{i}. {book}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b189fe1e",
   "metadata": {},
   "source": [
    "## Association_Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af608596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the UCI Machine Learning Repository\n",
    "import pandas as pd\n",
    "\n",
    "data_path = 'C:/Users/taek5/Desktop/TG/RecommenderSystems/data/online_retail/'\n",
    "online_retail_data = pd.read_excel(data_path + 'Online Retail.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5a24d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "online_retail_data['Description'] = online_retail_data['Description'].str.strip()\n",
    "online_retail_data = online_retail_data.dropna(axis = 0, subset = ['InvoiceNo'])\n",
    "online_retail_data['InvoiceNo'] = online_retail_data['InvoiceNo'].astype('str')\n",
    "online_retail_data = online_retail_data[~online_retail_data['InvoiceNo'].str.contains('C')] # 취소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58301545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taek5\\anaconda3\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:109: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Convert transaction data into a basker foramt\n",
    "basket = (online_retail_data[online_retail_data['Country'] == 'United Kingdom']\n",
    "          .groupby(['InvoiceNo', 'Description'])['Quantity']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('InvoiceNo'))\n",
    "\n",
    "# Convert the quantities into 0/1 (0: not in the basket, 1: in the basket)\n",
    "def encode_units(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >= 1:\n",
    "        return 1\n",
    "    \n",
    "basket_sets = basket.applymap(encode_units)\n",
    "\n",
    "# Use the Apriori algorithm to find frequent itemsets\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "frequent_itemsets = apriori(basket_sets, min_support = 0.03, use_colnames = True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric = 'lift', min_threshold = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5a1bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rules by a minimum lift and confidence\n",
    "filtered_rules = rules[(rules['lift'] >= 3.0) & (rules['confidence'] >= 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a886ac91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ALARM CLOCK BAKELIKE RED)</td>\n",
       "      <td>(ALARM CLOCK BAKELIKE GREEN)</td>\n",
       "      <td>0.030160</td>\n",
       "      <td>0.605376</td>\n",
       "      <td>12.900183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(ALARM CLOCK BAKELIKE GREEN)</td>\n",
       "      <td>(ALARM CLOCK BAKELIKE RED)</td>\n",
       "      <td>0.030160</td>\n",
       "      <td>0.642694</td>\n",
       "      <td>12.900183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(PINK REGENCY TEACUP AND SAUCER)</td>\n",
       "      <td>(GREEN REGENCY TEACUP AND SAUCER)</td>\n",
       "      <td>0.030910</td>\n",
       "      <td>0.820768</td>\n",
       "      <td>16.403939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(GREEN REGENCY TEACUP AND SAUCER)</td>\n",
       "      <td>(PINK REGENCY TEACUP AND SAUCER)</td>\n",
       "      <td>0.030910</td>\n",
       "      <td>0.617773</td>\n",
       "      <td>16.403939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(ROSES REGENCY TEACUP AND SAUCER)</td>\n",
       "      <td>(GREEN REGENCY TEACUP AND SAUCER)</td>\n",
       "      <td>0.037553</td>\n",
       "      <td>0.732497</td>\n",
       "      <td>14.639752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(GREEN REGENCY TEACUP AND SAUCER)</td>\n",
       "      <td>(ROSES REGENCY TEACUP AND SAUCER)</td>\n",
       "      <td>0.037553</td>\n",
       "      <td>0.750535</td>\n",
       "      <td>14.639752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(JUMBO  BAG BAROQUE BLACK WHITE)</td>\n",
       "      <td>(JUMBO BAG RED RETROSPOT)</td>\n",
       "      <td>0.030535</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>6.033290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(JUMBO BAG PINK POLKADOT)</td>\n",
       "      <td>(JUMBO BAG RED RETROSPOT)</td>\n",
       "      <td>0.042053</td>\n",
       "      <td>0.677308</td>\n",
       "      <td>6.523895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(JUMBO SHOPPER VINTAGE RED PAISLEY)</td>\n",
       "      <td>(JUMBO BAG RED RETROSPOT)</td>\n",
       "      <td>0.035196</td>\n",
       "      <td>0.579876</td>\n",
       "      <td>5.585425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(JUMBO STORAGE BAG SUKI)</td>\n",
       "      <td>(JUMBO BAG RED RETROSPOT)</td>\n",
       "      <td>0.037392</td>\n",
       "      <td>0.617699</td>\n",
       "      <td>5.949737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            antecedents                        consequents  \\\n",
       "0            (ALARM CLOCK BAKELIKE RED)       (ALARM CLOCK BAKELIKE GREEN)   \n",
       "1          (ALARM CLOCK BAKELIKE GREEN)         (ALARM CLOCK BAKELIKE RED)   \n",
       "2      (PINK REGENCY TEACUP AND SAUCER)  (GREEN REGENCY TEACUP AND SAUCER)   \n",
       "3     (GREEN REGENCY TEACUP AND SAUCER)   (PINK REGENCY TEACUP AND SAUCER)   \n",
       "4     (ROSES REGENCY TEACUP AND SAUCER)  (GREEN REGENCY TEACUP AND SAUCER)   \n",
       "5     (GREEN REGENCY TEACUP AND SAUCER)  (ROSES REGENCY TEACUP AND SAUCER)   \n",
       "6      (JUMBO  BAG BAROQUE BLACK WHITE)          (JUMBO BAG RED RETROSPOT)   \n",
       "8             (JUMBO BAG PINK POLKADOT)          (JUMBO BAG RED RETROSPOT)   \n",
       "10  (JUMBO SHOPPER VINTAGE RED PAISLEY)          (JUMBO BAG RED RETROSPOT)   \n",
       "12             (JUMBO STORAGE BAG SUKI)          (JUMBO BAG RED RETROSPOT)   \n",
       "\n",
       "     support  confidence       lift  \n",
       "0   0.030160    0.605376  12.900183  \n",
       "1   0.030160    0.642694  12.900183  \n",
       "2   0.030910    0.820768  16.403939  \n",
       "3   0.030910    0.617773  16.403939  \n",
       "4   0.037553    0.732497  14.639752  \n",
       "5   0.037553    0.750535  14.639752  \n",
       "6   0.030535    0.626374   6.033290  \n",
       "8   0.042053    0.677308   6.523895  \n",
       "10  0.035196    0.579876   5.585425  \n",
       "12  0.037392    0.617699   5.949737  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the association rules\n",
    "filtered_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9329b1",
   "metadata": {},
   "source": [
    "## Contents Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cb8e7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.66666667 0.40824829 0.81649658]\n",
      " [0.66666667 1.         0.81649658 0.40824829]\n",
      " [0.40824829 0.81649658 1.         0.        ]\n",
      " [0.81649658 0.40824829 0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Define the matrix\n",
    "matrix = np.array([[1, 1, 1, 0],\n",
    "                   [1, 0, 1, 1],\n",
    "                   [1, 0, 0, 1],\n",
    "                   [0, 1, 1, 0]])\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity_matrix = cosine_similarity(matrix)\n",
    "\n",
    "# Print the similarity matrix\n",
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddf1742",
   "metadata": {},
   "source": [
    "### Bag of Words 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "805dc8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 'love', 'watching', 'movies'], ['i', 'enjoy', 'reading', 'books'], ['i', 'love', 'reading', 'and', 'watching', 'movies']]\n",
      "\n",
      "\n",
      "[Counter({'i': 1, 'love': 1, 'watching': 1, 'movies': 1}), Counter({'i': 1, 'enjoy': 1, 'reading': 1, 'books': 1}), Counter({'i': 1, 'love': 1, 'reading': 1, 'and': 1, 'watching': 1, 'movies': 1})]\n",
      "\n",
      "\n",
      "Bag of Words representation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>love</th>\n",
       "      <th>watching</th>\n",
       "      <th>movies</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>reading</th>\n",
       "      <th>books</th>\n",
       "      <th>and</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Document 1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document 2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document 3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            i  love  watching  movies  enjoy  reading  books  and\n",
       "Document 1  1   1.0       1.0     1.0    0.0      0.0    0.0  0.0\n",
       "Document 2  1   0.0       0.0     0.0    1.0      1.0    1.0  0.0\n",
       "Document 3  1   1.0       1.0     1.0    0.0      1.0    0.0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Sample sentences\n",
    "documents = [\n",
    "    \"I love watching movies\",\n",
    "    \"I enjoy reading books\",\n",
    "    \"I love reading and watching movies\"\n",
    "]\n",
    "\n",
    "# Preprocess sentences: lower case and tokenize\n",
    "tokenized_documents = [doc.lower().split() for doc in documents]\n",
    "print(tokenized_documents)\n",
    "\n",
    "print('\\n')\n",
    "# Calculate word frequencies for each document\n",
    "word_frequencies = [Counter(doc) for doc in tokenized_documents]\n",
    "print(word_frequencies)\n",
    "\n",
    "print('\\n')\n",
    "# Create a DataFrame to display the results\n",
    "bow_df = pd.DataFrame(word_frequencies, index = ['Document 1', 'Document 2', 'Document 3']).fillna(0)\n",
    "print(\"Bag of Words representation:\")\n",
    "display(bow_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487223c5",
   "metadata": {},
   "source": [
    "### TF-IDF 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5fd6ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized_documents:\n",
      "[['i', 'love', 'watching', 'movies'], ['i', 'enjoy', 'reading', 'books'], ['i', 'love', 'reading', 'and', 'watching', 'movies']]\n",
      "\n",
      "\n",
      "[{'i': 0.25, 'love': 0.25, 'watching': 0.25, 'movies': 0.25}, {'i': 0.25, 'enjoy': 0.25, 'reading': 0.25, 'books': 0.25}, {'i': 0.16666666666666666, 'love': 0.16666666666666666, 'reading': 0.16666666666666666, 'and': 0.16666666666666666, 'watching': 0.16666666666666666, 'movies': 0.16666666666666666}]\n",
      "\n",
      "\n",
      "Term Frequencies DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>love</th>\n",
       "      <th>watching</th>\n",
       "      <th>movies</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>reading</th>\n",
       "      <th>books</th>\n",
       "      <th>and</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Document 1</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document 2</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document 3</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   i      love  watching    movies  enjoy   reading  books  \\\n",
       "Document 1  0.250000  0.250000  0.250000  0.250000   0.00  0.000000   0.00   \n",
       "Document 2  0.250000  0.000000  0.000000  0.000000   0.25  0.250000   0.25   \n",
       "Document 3  0.166667  0.166667  0.166667  0.166667   0.00  0.166667   0.00   \n",
       "\n",
       "                 and  \n",
       "Document 1  0.000000  \n",
       "Document 2  0.000000  \n",
       "Document 3  0.166667  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Inverse Document Frequencies DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>watching</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>reading</th>\n",
       "      <th>i</th>\n",
       "      <th>movies</th>\n",
       "      <th>love</th>\n",
       "      <th>books</th>\n",
       "      <th>and</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IDF</th>\n",
       "      <td>0.405465</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     watching     enjoy   reading    i    movies      love     books       and\n",
       "IDF  0.405465  1.098612  0.405465  0.0  0.405465  0.405465  1.098612  1.098612"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TF-IDF Values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'i': 0.0,\n",
       "  'love': 0.1013662770270411,\n",
       "  'watching': 0.1013662770270411,\n",
       "  'movies': 0.1013662770270411},\n",
       " {'i': 0.0,\n",
       "  'enjoy': 0.27465307216702745,\n",
       "  'reading': 0.1013662770270411,\n",
       "  'books': 0.27465307216702745},\n",
       " {'i': 0.0,\n",
       "  'love': 0.06757751801802739,\n",
       "  'reading': 0.06757751801802739,\n",
       "  'and': 0.1831020481113516,\n",
       "  'watching': 0.06757751801802739,\n",
       "  'movies': 0.06757751801802739}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# Sample sentences\n",
    "documents = [\n",
    "    \"I love watching movies\",\n",
    "    \"I enjoy reading books\",\n",
    "    \"I love reading and watching movies\"\n",
    "]\n",
    "\n",
    "# Preprocess sentences: lower case and tokenize\n",
    "tokenized_documents = [doc.lower().split() for doc in documents]\n",
    "print(\"tokenized_documents:\")\n",
    "print(tokenized_documents)\n",
    "print('\\n')\n",
    "\n",
    "# Calculate term frequency\n",
    "def term_frequency(doc):\n",
    "    term_count = Counter(doc)\n",
    "    \n",
    "    total_terms = len(doc)\n",
    "    return {term: count / total_terms for term, count in term_count.items()}\n",
    "\n",
    "tf_values = [term_frequency(doc) for doc in tokenized_documents]\n",
    "print(tf_values)\n",
    "print('\\n')\n",
    "\n",
    "tf_df = pd.DataFrame(tf_values, index = [\"Document 1\", \"Document 2\", \"Document 3\"]).fillna(0)\n",
    "print(\"Term Frequencies DataFrame:\")\n",
    "display(tf_df)\n",
    "print('\\n')\n",
    "\n",
    "# Calculate inverse document frequency\n",
    "def inverse_document_frequency(docs):\n",
    "    total_docs = len(docs)\n",
    "    \n",
    "    unique_terms = set(term for doc in docs for term in doc)\n",
    "    \n",
    "    term_doc_counts = {term: sum(1 for doc in docs if term in doc) for term in unique_terms}\n",
    "    \n",
    "    return {term: math.log(total_docs / count) for term, count in term_doc_counts.items()}\n",
    "\n",
    "idf_values = inverse_document_frequency(tokenized_documents)\n",
    "idf_df = pd.DataFrame([idf_values], index = ['IDF'])\n",
    "print(\"Inverse Document Frequencies DataFrame:\")\n",
    "display(idf_df)\n",
    "print('\\n')\n",
    "\n",
    "# Calculate TF-IDF\n",
    "def tf_idf(tf, idf):\n",
    "    return {term: tf_val * idf[term] for term, tf_val in tf.items()}\n",
    "\n",
    "tf_idf_values = [tf_idf(tf, idf_values) for tf in tf_values]\n",
    "print(\"TF-IDF Values:\")\n",
    "display(tf_idf_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beff3eb9",
   "metadata": {},
   "source": [
    "# ML_Based_Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a7ffd1",
   "metadata": {},
   "source": [
    "## Matrix_Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "375701f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the UCI Machine Learning Repository\n",
    "import pandas as pd\n",
    "\n",
    "data_path = 'C:/Users/taek5/Desktop/TG/RecommenderSystems/data/online_retail/'\n",
    "online_retail_data = pd.read_excel(data_path + 'Online Retail.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cdd4e5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "online_retail_data['CustomerID'] = online_retail_data['CustomerID'].astype('category')\n",
    "online_retail_data['StockCode'] = online_retail_data['StockCode'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84f41b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피벗 테이블 만들기 -> 너무 적은 인터렉션을 갖는 유저/아이템은 배제\n",
    "interaction_counts = online_retail_data.groupby('CustomerID')['StockCode'].count()\n",
    "online_retail_data = online_retail_data[online_retail_data['CustomerID'].isin(interaction_counts[interaction_counts > 10].index)]\n",
    "\n",
    "item_counts = online_retail_data['StockCode'].value_counts()\n",
    "online_retail_data = online_retail_data[online_retail_data['StockCode'].isin(item_counts[item_counts > 10].index)]\n",
    "\n",
    "pivot = online_retail_data.pivot_table(index = 'CustomerID', columns = 'StockCode', fill_value = 0, aggfunc = 'size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a7deeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implicit data로 변경\n",
    "pivot = (pivot > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3f45a729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# train/tset split\n",
    "test_ratio = 0.2\n",
    "train = pivot.copy()\n",
    "test = np.zeros(pivot.shape)\n",
    "\n",
    "for user in range(pivot.shape[0]):\n",
    "    test_interactions = np.random.choice(pivot.values[user, :].nonzero()[0],\n",
    "                                         size = int(test_ratio * np.sum(pivot.values[user, :])),\n",
    "                                         replace = False)\n",
    "    train.values[user, test_interactions] = 0.\n",
    "    test[user, test_interactions] = pivot.values[user, test_interactions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "908ab95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Convert train and test matrix into sparse matrix\n",
    "train_csr = coo_matrix(train.values)\n",
    "test_csr = coo_matrix(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c71a3cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_latent_factors = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b322af24",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "25f80a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# using sklearn Truncated SVD\n",
    "svd = TruncatedSVD(n_components = n_latent_factors, random_state = 42)\n",
    "train_svd = svd.fit_transform(train_csr)\n",
    "svd_pred1 = svd.inverse_transform(svd.transform(test_csr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "230565a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "# using svds from scipy\n",
    "u, sigma, vt = svds(train_csr.astype(float), n_latent_factors)\n",
    "svd_pred2 = np.dot(u, np.dot(np.diag(sigma), vt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a77086d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of the matrices: ((4372, 20), (20,), (20, 4070))\n"
     ]
    }
   ],
   "source": [
    "print(f'shapes of the matrices: {u.shape, sigma.shape, vt.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2d9e790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the predicted scores are in the range [0, 1]\n",
    "predicted_svd1 = (svd_pred1 - svd_pred1.min()) / (svd_pred1.max() - svd_pred1.min())\n",
    "predicted_svd2 = (svd_pred2 - svd_pred2.min()) / (svd_pred2.max() - svd_pred2.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "96513922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncated SVD RMSE:  0.16005063109387835\n",
      "SCIPY SVD RMSE:  0.4059451887511608\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate RMSE for SVD\n",
    "svd_rmse1 = np.sqrt(mean_squared_error(test_csr.toarray(), predicted_svd1))\n",
    "svd_rmse2 = np.sqrt(mean_squared_error(test_csr.toarray(), predicted_svd2))\n",
    "print('Truncated SVD RMSE: ', svd_rmse1)\n",
    "print('SCIPY SVD RMSE: ', svd_rmse2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee85bcb",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "61a0363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model = NMF(n_components = n_latent_factors, init = 'random', random_state = 0)\n",
    "\n",
    "W = model.fit_transform(train_csr)\n",
    "H = model.components_\n",
    "nmf_pred = np.dot(W, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1e0f8861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the predicted scores are in the range [0, 1]\n",
    "predicted_nmf = (nmf_pred - nmf_pred.min()) / (nmf_pred.max() - nmf_pred.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7a5ab93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF RMSE:  0.053694958342476236\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE for NMF\n",
    "nmf_rmse = np.sqrt(mean_squared_error(test_csr.toarray(), predicted_nmf))\n",
    "print('NMF RMSE: ', nmf_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e599cc73",
   "metadata": {},
   "source": [
    "### ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2369ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALS class 정의\n",
    "\n",
    "class ALS:\n",
    "    # 하이퍼 파라미터 지정\n",
    "    def __init__(self, factors=10, iterations=20, reg=0.01):\n",
    "        self.factors = factors\n",
    "        self.iterations = iterations\n",
    "        self.reg = reg\n",
    "    # 모델 적합 -> 평점 행렬 입력\n",
    "    def fit(self, ratings):\n",
    "        # 랜덤으로 user 수 * latent factor 형태의 행렬 생성\n",
    "        self.user_factors = np.random.random((ratings.shape[0], self.factors))\n",
    "        # 랜덤으로 item 수 * latent factor 형태의 행렬 생성\n",
    "        self.item_factors = np.random.random((ratings.shape[1], self.factors))\n",
    "        \n",
    "        # 사전에 지정한 iteration 수에 걸쳐서, 교차로 als_step 진행\n",
    "        for _ in range(self.iterations):\n",
    "            # user_factors 먼저 업데이트 \n",
    "            self.user_factors = self.als_step(ratings, self.user_factors, self.item_factors)\n",
    "            # 이어서 item_factors 업데이트\n",
    "            self.item_factors = self.als_step(ratings.T, self.item_factors, self.user_factors)\n",
    "    \n",
    "    # 교차로 업데이트하는 스텝 메서드\n",
    "    def als_step(self, ratings, solve_vecs, fixed_vecs):\n",
    "        # normal equation - 업데이트 되지 않을 user/item feature의 공분산 matrix\n",
    "        # feature가 주어진(고정된) 상태에서 최적의 해를 찾아 그 행렬을 새로운 factors로 사용\n",
    "        # 가령, user_factors가 고정되어 있을 때는 최적의 item_factors를 구하고, 반대도 마찬가지\n",
    "        A = fixed_vecs.T.dot(fixed_vecs) + np.eye(self.factors) * self.reg\n",
    "        b = ratings.dot(fixed_vecs)\n",
    "        A_inv = np.linalg.inv(A)\n",
    "        solve_vecs = b.dot(A_inv)\n",
    "        return solve_vecs\n",
    "\n",
    "    def predict(self):\n",
    "        pred = self.user_factors.dot(self.item_factors.T)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "14a73f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train ALS model\n",
    "als = ALS(factors = n_latent_factors, iterations = 100, reg = 0.01)\n",
    "als.fit(train_csr)\n",
    "\n",
    "# predict\n",
    "als_pred = als.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "263c0a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the predicted scores are in the range [0, 1]\n",
    "predicted_als = (als_pred - als_pred.min()) / (als_pred.max() - als_pred.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "06afee80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS RMSE:  0.37238415159097327\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE for ALS\n",
    "als_rmse = np.sqrt(mean_squared_error(test_csr.toarray(), predicted_als))\n",
    "print('ALS RMSE: ', als_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
